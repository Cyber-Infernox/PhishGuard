{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaOIR8Dvq3PO"
      },
      "source": [
        "# **Public Phishing URL Detection model API**\n",
        "\n",
        "*Final project of Machine Learning & Cybersecurity*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "62GP1VmlyiDb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7666b936-0f12-4614-d6f4-5823c9a9a109"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:132: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1Fre2MrpO6rvT0XAX3u5rhW5FRG-oGPAB\n",
            "From (redirected): https://drive.google.com/uc?id=1Fre2MrpO6rvT0XAX3u5rhW5FRG-oGPAB&confirm=t&uuid=f7329b54-94de-4428-a819-647fda255b02\n",
            "To: /content/dataset.sav\n",
            "100% 1.23G/1.23G [00:16<00:00, 74.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "# dataset.sav\n",
        "! gdown --id 1Fre2MrpO6rvT0XAX3u5rhW5FRG-oGPAB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "SUnS5xHy8NH7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7eac0fa-a230-4b4d-ab43-6d18340bc572"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (0.111.0)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi) (0.37.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.7.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (4.12.2)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from fastapi) (0.0.4)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (0.27.0)\n",
            "Requirement already satisfied: jinja2>=2.11.2 in /usr/local/lib/python3.10/dist-packages (from fastapi) (3.1.4)\n",
            "Requirement already satisfied: python-multipart>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from fastapi) (0.0.9)\n",
            "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from fastapi) (5.10.0)\n",
            "Requirement already satisfied: orjson>=3.2.1 in /usr/local/lib/python3.10/dist-packages (from fastapi) (3.10.5)\n",
            "Requirement already satisfied: email_validator>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.2.0)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (0.30.1)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi) (2.6.1)\n",
            "Requirement already satisfied: idna>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi) (3.7)\n",
            "Requirement already satisfied: typer>=0.12.3 in /usr/local/lib/python3.10/dist-packages (from fastapi-cli>=0.0.2->fastapi) (0.12.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.23.0->fastapi) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.2->fastapi) (2.1.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.18.4)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0->fastapi) (8.1.7)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0->fastapi) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0->fastapi) (1.0.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0->fastapi) (6.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0->fastapi) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0->fastapi) (0.22.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0->fastapi) (12.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.23.0->fastapi) (1.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (13.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (0.1.2)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (0.30.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (4.12.2)\n",
            "Requirement already satisfied: pickle5 in /usr/local/lib/python3.10/dist-packages (0.0.11)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (2.7.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic) (4.12.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.6.2)\n",
            "Requirement already satisfied: pypi-json in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: apeye>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from pypi-json) (1.4.1)\n",
            "Requirement already satisfied: packaging>=21.0 in /usr/local/lib/python3.10/dist-packages (from pypi-json) (24.1)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from pypi-json) (2.31.0)\n",
            "Requirement already satisfied: apeye-core>=1.0.0b2 in /usr/local/lib/python3.10/dist-packages (from apeye>=1.1.0->pypi-json) (1.1.5)\n",
            "Requirement already satisfied: domdf-python-tools>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from apeye>=1.1.0->pypi-json) (3.9.0)\n",
            "Requirement already satisfied: platformdirs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from apeye>=1.1.0->pypi-json) (4.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->pypi-json) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->pypi-json) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->pypi-json) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->pypi-json) (2024.6.2)\n",
            "Requirement already satisfied: natsort>=7.0.1 in /usr/local/lib/python3.10/dist-packages (from domdf-python-tools>=2.6.0->apeye>=1.1.0->pypi-json) (8.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.10/dist-packages (from domdf-python-tools>=2.6.0->apeye>=1.1.0->pypi-json) (4.12.2)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.1.6)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.10/dist-packages (4.8.0)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo) (2.6.1)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: python-whois in /usr/local/lib/python3.10/dist-packages (0.9.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from python-whois) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->python-whois) (1.16.0)\n",
            "Requirement already satisfied: sockets in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: tldextract in /usr/local/lib/python3.10/dist-packages (5.1.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from tldextract) (3.7)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from tldextract) (2.31.0)\n",
            "Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.10/dist-packages (from tldextract) (2.1.0)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from tldextract) (3.15.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->tldextract) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->tldextract) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->tldextract) (2024.6.2)\n",
            "Requirement already satisfied: tld in /usr/local/lib/python3.10/dist-packages (0.13)\n"
          ]
        }
      ],
      "source": [
        "!pip install fastapi\n",
        "!pip install uvicorn\n",
        "!pip install pickle5\n",
        "!pip install pydantic\n",
        "!pip install scikit-learn\n",
        "!pip install requests\n",
        "!pip install pypi-json\n",
        "!pip install pyngrok\n",
        "!pip install nest-asyncio\n",
        "!pip install pymongo\n",
        "!pip install python-dotenv\n",
        "!pip install python-whois\n",
        "!pip install sockets\n",
        "!pip install tldextract\n",
        "!pip install tld"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "KE0pNNBX9u5n"
      },
      "outputs": [],
      "source": [
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "import pickle\n",
        "import json\n",
        "import uvicorn\n",
        "from pyngrok import ngrok\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "import nest_asyncio\n",
        "import datetime\n",
        "import ipaddress\n",
        "import re\n",
        "from googlesearch import search\n",
        "import requests\n",
        "import whois\n",
        "import ssl\n",
        "import socket\n",
        "import urllib.parse\n",
        "import tldextract\n",
        "import numpy as np\n",
        "import os\n",
        "from tld import get_tld\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "from starlette.middleware.cors import CORSMiddleware"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Z5A2tDL0Buo8"
      },
      "outputs": [],
      "source": [
        "def get_url_length(url):\n",
        "    return len(url)\n",
        "\n",
        "def get_domain_length(url):\n",
        "    parsed_url = urlparse(url)\n",
        "    domain = parsed_url.netloc\n",
        "    domain_length = len(domain)\n",
        "    return domain_length\n",
        "\n",
        "def is_domain_ip(url):\n",
        "    try:\n",
        "        parsed_url = urlparse(url)\n",
        "        domain = parsed_url.netloc  # Extract the domain part from the URL\n",
        "        ipaddress.ip_address(domain)  # Check if the domain is a valid IP address\n",
        "        return 1\n",
        "    except ValueError:\n",
        "        return 0\n",
        "\n",
        "def tld_length(tld):\n",
        "    if tld:\n",
        "        return len(tld)\n",
        "    else:\n",
        "        return -1\n",
        "\n",
        "def char_continuation_rate(url):\n",
        "    continuous_count = 0\n",
        "    total_count = len(url)\n",
        "\n",
        "    for i in range(1, len(url)):\n",
        "        if url[i] == url[i - 1]:\n",
        "            continuous_count += 1\n",
        "\n",
        "    if total_count > 0:\n",
        "        continuation_rate = continuous_count / total_count\n",
        "    else:\n",
        "        continuation_rate = 0.0\n",
        "\n",
        "    return continuation_rate\n",
        "\n",
        "def url_character_prob(url):\n",
        "    char_count = {}\n",
        "    total_chars = len(url)\n",
        "\n",
        "    for char in url:\n",
        "        char_count[char] = char_count.get(char, 0) + 1\n",
        "\n",
        "    char_prob = {char: count / total_chars for char, count in char_count.items()}\n",
        "\n",
        "    # Calculate the mean probability\n",
        "    mean_prob = sum(char_prob.values()) / len(char_prob)\n",
        "\n",
        "    return mean_prob\n",
        "\n",
        "def number_of_subdomains(url):\n",
        "    parsed_url = urlparse(url)\n",
        "    domain = parsed_url.netloc\n",
        "\n",
        "    if domain:\n",
        "        num_subdomains = domain.count('.')\n",
        "    else:\n",
        "        num_subdomains = 0\n",
        "\n",
        "    return num_subdomains\n",
        "\n",
        "def has_obfuscation(url):\n",
        "    # List of common obfuscation patterns to detect\n",
        "    obfuscation_patterns = [\n",
        "        '%',                     # Percentage encoding\n",
        "        '\\\\x',                   # Hexadecimal encoding\n",
        "        '&#',                    # HTML entity encoding\n",
        "        '\\\\u',                   # Unicode encoding (corrected)\n",
        "        'javascript:',           # JavaScript code injection\n",
        "        'data:',                 # Data URL scheme\n",
        "        'blob:',                 # Blob URL scheme\n",
        "        'onerror', 'onload',     # Event handlers\n",
        "        'document.cookie',       # Access to cookies\n",
        "        'eval(', 'exec(',        # Evaluation functions\n",
        "        'unescape(',             # Unescaping\n",
        "        'String.fromCharCode(', # Constructing strings\n",
        "        'String.fromCodePoint(', # Constructing strings\n",
        "        'String.raw(',           # Constructing strings\n",
        "    ]\n",
        "\n",
        "    # Check if any obfuscation pattern is found in the URL\n",
        "    for pattern in obfuscation_patterns:\n",
        "        if pattern in url.lower():\n",
        "            return 1  # Obfuscation detected\n",
        "\n",
        "    return 0  # No obfuscation detected\n",
        "\n",
        "def number_of_obfuscated_chars(url):\n",
        "    # List of common obfuscation patterns to detect\n",
        "    obfuscation_patterns = [\n",
        "        '%',     # Percentage encoding\n",
        "        '&#',    # HTML entity encoding\n",
        "        '\\\\u',   # Unicode encoding\n",
        "        '\\\\x',   # Hexadecimal encoding\n",
        "        '\\u202E', '\\u200E', '\\u200F', '\\u202A', '\\u202B', '\\u202C'  # Directional formatting characters\n",
        "    ]\n",
        "\n",
        "    # Initialize the counter for obfuscated characters\n",
        "    num_obfuscated_chars = 0\n",
        "\n",
        "    # Check for each obfuscation pattern in the URL\n",
        "    for pattern in obfuscation_patterns:\n",
        "        # Count the occurrences of the obfuscation pattern in the URL\n",
        "        num_obfuscated_chars += url.lower().count(pattern)\n",
        "\n",
        "    return num_obfuscated_chars\n",
        "\n",
        "def obfuscation_ratio(url):\n",
        "    # List of common obfuscation patterns to detect\n",
        "    obfuscation_patterns = [\n",
        "        '%',     # Percentage encoding\n",
        "        '&#',    # HTML entity encoding\n",
        "        '\\\\u',   # Unicode encoding\n",
        "        '\\\\x',   # Hexadecimal encoding\n",
        "        '\\u202E', '\\u200E', '\\u200F', '\\u202A', '\\u202B', '\\u202C'  # Directional formatting characters\n",
        "    ]\n",
        "\n",
        "    # Count the total number of characters in the URL\n",
        "    total_chars = len(url)\n",
        "\n",
        "    # Initialize the counter for obfuscated characters\n",
        "    num_obfuscated_chars = 0\n",
        "\n",
        "    # Check for each obfuscation pattern in the URL\n",
        "    for pattern in obfuscation_patterns:\n",
        "        # Count the occurrences of the obfuscation pattern in the URL\n",
        "        num_obfuscated_chars += url.lower().count(pattern)\n",
        "\n",
        "    # Calculate the obfuscation ratio\n",
        "    obfuscation_ratio = num_obfuscated_chars / total_chars if total_chars > 0 else 0.0\n",
        "\n",
        "    return obfuscation_ratio\n",
        "\n",
        "def number_of_letters_in_url(url):\n",
        "    letters = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "\n",
        "    num_letters = sum(url.count(letter) for letter in letters)\n",
        "\n",
        "    return num_letters\n",
        "\n",
        "def letter_ratio_in_url(url):\n",
        "    num_letters = number_of_letters_in_url(url)\n",
        "\n",
        "    total_chars = len(url)\n",
        "\n",
        "    if total_chars > 0:\n",
        "        letter_ratio = num_letters / total_chars\n",
        "    else:\n",
        "        letter_ratio = 0.0\n",
        "\n",
        "    return letter_ratio\n",
        "\n",
        "def number_of_digits_in_url(url):\n",
        "    digits = '0123456789'\n",
        "\n",
        "    num_digits = sum(url.count(digit) for digit in digits)\n",
        "\n",
        "    return num_digits\n",
        "\n",
        "def digit_ratio_in_url(url):\n",
        "    num_digits = number_of_digits_in_url(url)\n",
        "\n",
        "    total_chars = len(url)\n",
        "\n",
        "    if total_chars > 0:\n",
        "        digit_ratio = num_digits / total_chars\n",
        "    else:\n",
        "        digit_ratio = 0.0\n",
        "\n",
        "    return digit_ratio\n",
        "\n",
        "def number_of_ampersand_in_url(url):\n",
        "    num_ampersand = url.count('&')\n",
        "\n",
        "    return num_ampersand\n",
        "\n",
        "def number_of_other_special_chars_in_url(url):\n",
        "    allowed_chars = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789./:?&=%'\n",
        "\n",
        "    num_other_special_chars = sum(1 for char in url if char not in allowed_chars)\n",
        "\n",
        "    return num_other_special_chars\n",
        "\n",
        "def special_char_ratio_in_url(url):\n",
        "    num_special_chars = number_of_other_special_chars_in_url(url)\n",
        "\n",
        "    total_chars = len(url)\n",
        "\n",
        "    if total_chars > 0:\n",
        "        special_char_ratio = num_special_chars / total_chars\n",
        "    else:\n",
        "        special_char_ratio = 0.0\n",
        "\n",
        "    return special_char_ratio\n",
        "\n",
        "def is_https(url):\n",
        "    # Check if the URL starts with \"https://\"\n",
        "    if url.startswith(\"https://\"):\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def calculate_tld_legitimate_prop(url):\n",
        "    try:\n",
        "        # Get the Top-Level Domain (TLD) from the URL\n",
        "        tld = get_tld(url, fail_silently=True)\n",
        "\n",
        "        # List of commonly recognized TLDs used by legitimate websites\n",
        "        legitimate_tlds = ['com', 'net', 'org', 'edu', 'gov']\n",
        "\n",
        "        # Check if the extracted TLD is in the list of legitimate TLDs\n",
        "        if tld in legitimate_tlds:\n",
        "            return 1.0  # TLD is considered legitimate\n",
        "        else:\n",
        "            return 0.0  # TLD is not considered legitimate\n",
        "    except:\n",
        "        return -1  # Error: Unable to extract TLD\n",
        "\n",
        "#Use of IP or not in domain\n",
        "def having_ip_address(url):\n",
        "    match = re.search(\n",
        "        '(([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.'\n",
        "        '([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\/)|'  # IPv4\n",
        "        '((0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\/)' # IPv4 in hexadecimal\n",
        "        '(?:[a-fA-F0-9]{1,4}:){7}[a-fA-F0-9]{1,4}', url)  # Ipv6\n",
        "    if match:\n",
        "        # print match.group()\n",
        "        return 1\n",
        "    else:\n",
        "        # print 'No matching pattern found'\n",
        "        return 0\n",
        "\n",
        "def abnormal_url(url):\n",
        "    hostname = urlparse(url).hostname\n",
        "    hostname = str(hostname)\n",
        "    match = re.search(hostname, url)\n",
        "    if match:\n",
        "        # print match.group()\n",
        "        return 1\n",
        "    else:\n",
        "        # print 'No matching pattern found'\n",
        "        return 0\n",
        "\n",
        "def count_per(url):\n",
        "    return url.count('%')\n",
        "\n",
        "def count_ques(url):\n",
        "    return url.count('?')\n",
        "\n",
        "def count_hyphen(url):\n",
        "    return url.count('-')\n",
        "\n",
        "def count_equal(url):\n",
        "    return url.count('=')\n",
        "\n",
        "def count_www(url):\n",
        "  url.count('www')\n",
        "  return url.count('www')\n",
        "\n",
        "def count_atrate(url):\n",
        "  return url.count('@')\n",
        "\n",
        "def no_of_dir(url):\n",
        "  urldir = urlparse(url).path\n",
        "  return urldir.count('/')\n",
        "\n",
        "def no_of_embed(url):\n",
        "  urldir = urlparse(url).path\n",
        "  return urldir.count('//')\n",
        "\n",
        "def count_https(url):\n",
        "    return url.count('https')\n",
        "\n",
        "def count_http(url):\n",
        "    return url.count('http')\n",
        "\n",
        "def count_dot(url):\n",
        "  count_dot = url.count('.')\n",
        "  return count_dot\n",
        "\n",
        "def shortening_service(url):\n",
        "    match = re.search('bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|'\n",
        "                      'yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|'\n",
        "                      'short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|'\n",
        "                      'doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|'\n",
        "                      'db\\.tt|qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|'\n",
        "                      'q\\.gs|is\\.gd|po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|'\n",
        "                      'x\\.co|prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|'\n",
        "                      'tr\\.im|link\\.zip\\.net',\n",
        "                      url)\n",
        "    if match:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def hostname_length(url):\n",
        "    return len(urlparse(url).netloc)\n",
        "\n",
        "def suspicious_words(url):\n",
        "    match = re.search('PayPal|login|signin|bank|account|update|free|lucky|service|bonus|ebayisapi|webscr',\n",
        "                      url)\n",
        "    if match:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def digit_count(url):\n",
        "    digits = 0\n",
        "    for i in url:\n",
        "        if i.isnumeric():\n",
        "            digits = digits + 1\n",
        "    return digits\n",
        "\n",
        "def letter_count(url):\n",
        "    letters = 0\n",
        "    for i in url:\n",
        "        if i.isalpha():\n",
        "            letters = letters + 1\n",
        "    return letters\n",
        "\n",
        "def google_index(url):\n",
        "  site = search(url, 5)\n",
        "  return 1 if site else 0\n",
        "\n",
        "def fd_length(url):\n",
        "    urlpath= urlparse(url).path\n",
        "    try:\n",
        "        return len(urlpath.split('/')[1])\n",
        "    except:\n",
        "        return 0\n",
        "\n",
        "# Request functions\n",
        "\n",
        "# Function to check if the URL is accessible\n",
        "def check_url_access(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        return 1  # Return 1 if the URL is accessible\n",
        "    except requests.exceptions.RequestException:\n",
        "        return 0  # Return 0 if there's an error accessing the URL\n",
        "\n",
        "# Function to check if the URL is redirected\n",
        "def check_redirect(url):\n",
        "    try:\n",
        "        response = requests.get(url, allow_redirects=False)\n",
        "        if response.status_code == 301 or response.status_code == 302:\n",
        "            return 0  # Return 0 if the URL is redirected\n",
        "        else:\n",
        "            return 1  # Return 1 if the URL is not redirected\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error accessing {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Function to send an HTTP request to the given URL and retrieve the response\n",
        "def send_http_request(url):\n",
        "    try:\n",
        "        response = requests.get(url, timeout=10)  # Set a timeout for the request\n",
        "        if response.status_code == 200:\n",
        "            return 1 if not analyze_content(response) else 0\n",
        "        else:\n",
        "            print(f\"Error accessing {url}: Status code {response.status_code}\")\n",
        "            return None\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error accessing {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Function to analyze the content of the response for phishing indicators\n",
        "def analyze_content(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        if response.status_code == 200:\n",
        "            content = response.text\n",
        "            # Implement content analysis logic here\n",
        "            # Example: Check for presence of known phishing keywords or patterns\n",
        "            phishing_keywords = ['login', 'password', 'bank', 'secure']\n",
        "            for keyword in phishing_keywords:\n",
        "                if re.search(keyword, content, re.IGNORECASE):\n",
        "                    return 0  # Phishing indicator found\n",
        "            return 1  # No phishing indicator found\n",
        "        else:\n",
        "            print(f\"Error: Unable to fetch content from {url}. Status code: {response.status_code}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error analyzing content for {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "def verify_ssl_certificate(url):\n",
        "    try:\n",
        "        context = ssl.create_default_context()\n",
        "        with socket.create_connection((url, 443)) as sock:\n",
        "            with context.wrap_socket(sock, server_hostname=url) as ssock:\n",
        "                cert = ssock.getpeercert()\n",
        "                if cert:\n",
        "                    # Check if the certificate is valid and issued by a trusted CA\n",
        "                    if ssl.match_hostname(cert, url):\n",
        "                        # Check if the certificate is not expired\n",
        "                        cert_not_after = datetime.datetime.strptime(cert['notAfter'], \"%b %d %H:%M:%S %Y %Z\")\n",
        "                        if cert_not_after > datetime.datetime.now():\n",
        "                            return 1  # Valid SSL certificate\n",
        "                        else:\n",
        "                            return 0  # Expired SSL certificate\n",
        "                    else:\n",
        "                        return 0  # Certificate does not match hostname\n",
        "                else:\n",
        "                    return 0  # No certificate available\n",
        "    except Exception as e:\n",
        "        print(f\"Error verifying SSL certificate for {url}: {e}\")\n",
        "        return None  # Error occurred\n",
        "\n",
        "def query_whois(url):\n",
        "    try:\n",
        "        # Extract domain from the URL\n",
        "        parsed_url = urlparse(url)\n",
        "        domain = parsed_url.netloc\n",
        "\n",
        "        # Perform WHOIS query for the extracted domain\n",
        "        w = whois.whois(domain)\n",
        "\n",
        "        if w:\n",
        "            # Check if WHOIS information indicates the domain is legitimate\n",
        "            # Note: WHOIS information alone might not be sufficient for a definitive conclusion\n",
        "            if 'creation_date' in w and 'expiration_date' in w:\n",
        "                return 1  # Legitimate domain\n",
        "            else:\n",
        "                return 0  # Suspicious domain\n",
        "        else:\n",
        "            return 0  # Suspicious domain\n",
        "    except Exception as e:\n",
        "        # Handle any errors that occur during the WHOIS query\n",
        "        print(f\"Error querying WHOIS information for {domain}: {e}\")\n",
        "        return 0  # Suspicious domain due to error\n",
        "\n",
        "def check_domain_reputation(url):\n",
        "    # Extract domain from the URL\n",
        "    parsed_url = urlparse(url)\n",
        "    domain = parsed_url.netloc\n",
        "\n",
        "    # Example: Using a hypothetical API for domain reputation check\n",
        "    api_url = \"https://example.com/domain-reputation-api\"\n",
        "    payload = {'domain': domain}\n",
        "\n",
        "    try:\n",
        "        response = requests.get(api_url, params=payload)\n",
        "        if response.status_code == 200:\n",
        "            result = response.json()\n",
        "            if result['blacklisted']:\n",
        "                return 0  # Domain is blacklisted\n",
        "            else:\n",
        "                return 1  # Domain is not blacklisted\n",
        "        else:\n",
        "            # API request failed, return an error code or handle the error as needed\n",
        "            return -1  # Error occurred\n",
        "    except Exception as e:\n",
        "        # Handle exceptions such as network errors\n",
        "        print(\"Exception occurred:\", e)\n",
        "        return -1  # Error occurred\n",
        "\n",
        "def check_url_blacklist(url):\n",
        "    # Example: Using a hypothetical API for URL blacklist check\n",
        "    api_url = \"https://example.com/blacklist-api\"\n",
        "    payload = {'url': url}\n",
        "    try:\n",
        "        response = requests.get(api_url, params=payload)\n",
        "        if response.status_code == 200:\n",
        "            result = response.json()\n",
        "            if result['blacklisted']:\n",
        "                return 0  # Phishing URL\n",
        "            else:\n",
        "                return 1  # Safe URL\n",
        "        else:\n",
        "            # API request failed, return an error code or handle the error as needed\n",
        "            return -1  # Error occurred\n",
        "    except Exception as e:\n",
        "        # Handle exceptions such as network errors\n",
        "        print(\"Exception occurred:\", e)\n",
        "        return -1  # Error occurred\n",
        "\n",
        "# Function to analyze the IP address associated with the URL\n",
        "def analyze_ip_address(url):\n",
        "    try:\n",
        "        # Extract domain from the URL\n",
        "        domain = urllib.parse.urlparse(url).netloc\n",
        "\n",
        "        # Get the IP address associated with the domain\n",
        "        ip_address = socket.gethostbyname(domain)\n",
        "\n",
        "        # Check the IP address against threat intelligence sources\n",
        "        if check_blacklist(ip_address):\n",
        "            return 1  # Malicious IP address\n",
        "        else:\n",
        "            return 0  # Clean IP address\n",
        "    except Exception as e:\n",
        "        print(f\"Error analyzing IP address for {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "def check_blacklist(ip_address):\n",
        "    # Example: Check against a public blacklist\n",
        "    blacklist_url = f\"https://www.abuseipdb.com/check/{ip_address}\"\n",
        "    try:\n",
        "        response = requests.get(blacklist_url)\n",
        "        if response.status_code == 200:\n",
        "            # Check if the IP address is listed in the blacklist\n",
        "            if \"This IP address has been reported\" in response.text:\n",
        "                return True\n",
        "            else:\n",
        "                return False\n",
        "        else:\n",
        "            print(f\"Error checking blacklist for {ip_address}: Status code {response.status_code}\")\n",
        "            return False\n",
        "    except Exception as e:\n",
        "        print(f\"Error checking blacklist for {ip_address}: {e}\")\n",
        "        return False\n",
        "\n",
        "# Function to handle different user-agent strings to evade detection\n",
        "def spoof_user_agent(url):\n",
        "    try:\n",
        "        custom_user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.9999.99 Safari/537.36\"\n",
        "        headers = {\n",
        "            'User-Agent': custom_user_agent\n",
        "        }\n",
        "        response = requests.get(url, headers=headers, timeout=10)  # Set a timeout for the request\n",
        "        if response.status_code == 200:\n",
        "            return 1 if not analyze_content(response) else 0\n",
        "        else:\n",
        "            print(f\"Error accessing {url}: Status code {response.status_code}\")\n",
        "            return None\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error accessing {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Function to handle sessions and cookies\n",
        "def handle_sessions(url):\n",
        "    session = requests.Session()\n",
        "    try:\n",
        "        response = session.get(url, timeout=10)  # Set a timeout for the request\n",
        "        if response.status_code == 200:\n",
        "            return 1 if not analyze_content(response) else 0\n",
        "        else:\n",
        "            print(f\"Error accessing {url}: Status code {response.status_code}\")\n",
        "            return None\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error accessing {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Function to handle request timeouts\n",
        "def handle_request_timeout(url, timeout=5):\n",
        "    try:\n",
        "        response = requests.get(url, timeout=timeout)\n",
        "        if response.status_code == 200:\n",
        "            return 1 if not analyze_content(response) else 0\n",
        "        else:\n",
        "            print(f\"Error accessing {url}: Status code {response.status_code}\")\n",
        "            return None\n",
        "    except requests.exceptions.Timeout:\n",
        "        print(f\"Timeout accessing {url}\")\n",
        "        return 0  # Treat as clean (no phishing indicators) due to timeout\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error accessing {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Function to perform more advanced checks based on TLD and subdomain\n",
        "def advanced_url_analysis(url):\n",
        "    try:\n",
        "        # Extract domain and subdomain information from the URL\n",
        "        extracted = tldextract.extract(url)\n",
        "        domain = extracted.domain\n",
        "        subdomain = extracted.subdomain\n",
        "\n",
        "        # Check if the domain or subdomain contains known malicious patterns\n",
        "        if check_malicious_pattern(domain) or check_malicious_pattern(subdomain):\n",
        "            return 0  # Phishing indicator found\n",
        "        else:\n",
        "            # Query WHOIS information for the domain\n",
        "            if query_whois(domain):\n",
        "                return 1  # Legitimate domain\n",
        "            else:\n",
        "                return 0  # Phishing indicator found\n",
        "    except Exception as e:\n",
        "        print(f\"Error performing advanced URL analysis for {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "def check_malicious_pattern(text):\n",
        "    # Implement logic to check for known malicious patterns in text\n",
        "    malicious_patterns = ['paypal', 'security', 'login', 'bank', 'phish']\n",
        "    for pattern in malicious_patterns:\n",
        "        if pattern in text.lower():\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def query_whois(domain):\n",
        "    try:\n",
        "        w = whois.whois(domain)\n",
        "        if w:\n",
        "            # Check if WHOIS information indicates the domain is legitimate\n",
        "            if 'creation_date' in w and 'expiration_date' in w:\n",
        "                return True\n",
        "            else:\n",
        "                return False\n",
        "        else:\n",
        "            return False\n",
        "    except Exception as e:\n",
        "        print(f\"Error querying WHOIS information for {domain}: {e}\")\n",
        "        return False\n",
        "\n",
        "def get_main_website_url(long_url):\n",
        "    # Parse the URL to extract its components\n",
        "    parsed_url = urlparse(long_url)\n",
        "\n",
        "    # Construct the main website URL\n",
        "    main_website_url = f\"{parsed_url.scheme}://{parsed_url.netloc}/\"\n",
        "\n",
        "    return main_website_url\n",
        "\n",
        "def mainly(url):\n",
        "\n",
        "    status = []\n",
        "\n",
        "    status.append(get_url_length(url))\n",
        "    status.append(get_domain_length(url))\n",
        "    status.append(is_domain_ip(url))\n",
        "    tld = get_tld(url,fail_silently=True)\n",
        "    status.append(tld_length(tld))\n",
        "    status.append(char_continuation_rate(url))\n",
        "    status.append(url_character_prob(url))\n",
        "    status.append(number_of_subdomains(url))\n",
        "    status.append(has_obfuscation(url))\n",
        "    status.append(number_of_obfuscated_chars(url))\n",
        "    status.append(obfuscation_ratio(url))\n",
        "    status.append(number_of_letters_in_url(url))\n",
        "    status.append(letter_ratio_in_url(url))\n",
        "    status.append(number_of_digits_in_url(url))\n",
        "    status.append(digit_ratio_in_url(url))\n",
        "    status.append(number_of_ampersand_in_url(url))\n",
        "    status.append(number_of_other_special_chars_in_url(url))\n",
        "    status.append(special_char_ratio_in_url(url))\n",
        "    status.append(is_https(url))\n",
        "    status.append(calculate_tld_legitimate_prop(url))\n",
        "    status.append(having_ip_address(url))\n",
        "    status.append(abnormal_url(url))\n",
        "    status.append(count_per(url))\n",
        "    status.append(count_ques(url))\n",
        "    status.append(count_hyphen(url))\n",
        "    status.append(count_equal(url))\n",
        "    status.append(count_www(url))\n",
        "    status.append(count_atrate(url))\n",
        "    status.append(no_of_dir(url))\n",
        "    status.append(no_of_embed(url))\n",
        "    status.append(count_https(url))\n",
        "    status.append(count_dot(url))\n",
        "    status.append(count_http(url))\n",
        "    status.append(shortening_service(url))\n",
        "    status.append(hostname_length(url))\n",
        "    status.append(suspicious_words(url))\n",
        "    status.append(digit_count(url))\n",
        "    status.append(letter_count(url))\n",
        "    status.append(google_index(url))\n",
        "    status.append(fd_length(url))\n",
        "\n",
        "    return status\n",
        "\n",
        "def get_prediction_from_url(test_url):\n",
        "\n",
        "    if(check_url_access(test_url) == 0):\n",
        "        return \"PHISHING\"\n",
        "\n",
        "    if(check_url_blacklist(test_url) == 0):\n",
        "        return \"PHISHING\"\n",
        "\n",
        "    if(verify_ssl_certificate(test_url) == 0):\n",
        "        return \"PHISHING\"\n",
        "\n",
        "    if(send_http_request(test_url) == 0):\n",
        "        return \"PHISHING\"\n",
        "\n",
        "    if(check_domain_reputation(test_url) == 0):\n",
        "        return \"PHISHING\"\n",
        "\n",
        "    if(spoof_user_agent(test_url) == 0):\n",
        "        return \"PHISHING\"\n",
        "\n",
        "    if(handle_sessions(test_url) == 0):\n",
        "        return \"PHISHING\"\n",
        "\n",
        "    if(handle_request_timeout(test_url, timeout=5) == 0):\n",
        "        return \"PHISHING\"\n",
        "\n",
        "    if(advanced_url_analysis(test_url) == 0):\n",
        "        return \"PHISHING\"\n",
        "\n",
        "    #if(analyze_ip_address(test_url) == 0):\n",
        "        #return \"PHISHING\"\n",
        "\n",
        "    #if(query_whois(test_url) == 0):\n",
        "        #return \"PHISHING\"\n",
        "\n",
        "    #if(analyze_content(test_url) == 0):\n",
        "        #return \"PHISHING\"\n",
        "\n",
        "    test_url = get_main_website_url(test_url)\n",
        "\n",
        "    features_test = mainly(test_url)\n",
        "\n",
        "    # Due to updates to scikit-learn, we now need a 2D array as a parameter to the predict function.\n",
        "    features_test = np.array(features_test).reshape((1, -1))\n",
        "\n",
        "    pred = loaded_model.predict(features_test)\n",
        "\n",
        "    return pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "t9Uqoplr-ES3"
      },
      "outputs": [],
      "source": [
        "app = FastAPI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "BQCwDg5M-GYk"
      },
      "outputs": [],
      "source": [
        "# Allow all origins, all methods, and all headers\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],  # Allow any origin\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],  # Allow all HTTP methods\n",
        "    allow_headers=[\"*\"],  # Allow all headers\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "m4_isbg1-LoI"
      },
      "outputs": [],
      "source": [
        "class model_input(BaseModel):\n",
        "    url : str"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "!pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "qk1jcSRcfDtI",
        "outputId": "963fdbf6-2321-4c0c-cbcf-289b12456ed1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ad539aba-d6fd-456e-b8f5-3560a62ad1ad\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ad539aba-d6fd-456e-b8f5-3560a62ad1ad\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving .env to .env\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "YjtwemIBAocg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from pymongo import MongoClient\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv(\".env\")\n",
        "\n",
        "# Get environment variables\n",
        "MONGO_URI = os.getenv(\"MONGO_URI\")\n",
        "MONGO_PREDICT_DB = os.getenv(\"MONGO_PREDICT_DB\")\n",
        "MONGO_PREDICT_COLLECTION = os.getenv(\"MONGO_PREDICT_COLLECTION\")\n",
        "\n",
        "# Connect to MongoDB\n",
        "try:\n",
        "    client = MongoClient(MONGO_URI)\n",
        "    db = client[MONGO_PREDICT_DB]\n",
        "    collection = db[MONGO_PREDICT_COLLECTION]\n",
        "    connection_status = True\n",
        "except Exception as e:\n",
        "    connection_status = False\n",
        "\n",
        "# Function to check if URL exists in the database and return its type\n",
        "def check_url_type(url):\n",
        "    if not connection_status:\n",
        "        return False\n",
        "\n",
        "    result = collection.find_one({\"url\": url})\n",
        "    if result:\n",
        "        return result[\"type\"]\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def add_url_to_database(url, url_type):\n",
        "    if not connection_status:\n",
        "        return False\n",
        "\n",
        "    try:\n",
        "        collection.insert_one({\"url\": url, \"type\": url_type})\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "TxPT5r75-fap"
      },
      "outputs": [],
      "source": [
        "# loading the saved model\n",
        "loaded_model = pickle.load(open('/content/dataset.sav','rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "cBwGCNRx_KO0"
      },
      "outputs": [],
      "source": [
        "@app.post('/url_prediction')\n",
        "def url_pred(input_parameters : model_input):\n",
        "    input_data = input_parameters.json()\n",
        "    input_dictionary = json.loads(input_data)\n",
        "\n",
        "    url = input_dictionary['url']\n",
        "\n",
        "    input_list = [url]\n",
        "\n",
        "    url_type = check_url_type(url)\n",
        "    if url_type:\n",
        "        if url_type == \"benign\":\n",
        "          return f\"SAFE\"\n",
        "        else:\n",
        "          return f\"PHISHING\"\n",
        "    else:\n",
        "        prediction = get_prediction_from_url(url)\n",
        "\n",
        "        if prediction[0] == 0:\n",
        "            diagnosis = \"benign\"\n",
        "\n",
        "        elif prediction[0] == 1:\n",
        "            diagnosis = \"phishing\"\n",
        "\n",
        "        # Add URL and its type to the database\n",
        "        if add_url_to_database(url, diagnosis):\n",
        "            return diagnosis\n",
        "        else:\n",
        "            return \"Failure\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "jzprK7q5GNLA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4781531-6012-42a5-9b90-6869d6937359"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken 2fRwWS2qV8fmdyBPkzohLCdwBXt_6xSeFsiPkbrwJF5Z938ur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "vy-i3x90A63n",
        "outputId": "193d12aa-af4e-4e23-ded2-5bb725bb0db8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: https://1601-35-221-6-56.ngrok-free.app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [37825]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     2405:201:8004:78ff:c498:9241:eb50:58f1:0 - \"OPTIONS /url_prediction HTTP/1.1\" 200 OK\n",
            "INFO:     2405:201:8004:78ff:c498:9241:eb50:58f1:0 - \"POST /url_prediction HTTP/1.1\" 200 OK\n",
            "Error verifying SSL certificate for https://smallpdf.com/merge-pdf: [Errno -2] Name or service not known\n",
            "Error analyzing content for <Response [200]>: Failed to parse: <Response [200]>\n",
            "Error analyzing content for <Response [200]>: Failed to parse: <Response [200]>\n",
            "Error analyzing content for <Response [200]>: Failed to parse: <Response [200]>\n",
            "Error analyzing content for <Response [200]>: Failed to parse: <Response [200]>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     2405:201:8004:78ff:c498:9241:eb50:58f1:0 - \"POST /url_prediction HTTP/1.1\" 200 OK\n",
            "INFO:     2405:201:8004:78ff:c498:9241:eb50:58f1:0 - \"POST /url_prediction HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2024-06-29T10:27:41+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8000-fd7a205a-da72-4042-bef8-b789f6c36c20 acceptErr=\"failed to accept connection: Listener closed\"\n",
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [37825]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-a1a31a32c385>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Public URL:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngrok_tunnel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublic_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnest_asyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0muvicorn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/uvicorn/main.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(app, host, port, uds, fd, loop, http, ws, ws_max_size, ws_max_queue, ws_ping_interval, ws_ping_timeout, ws_per_message_deflate, lifespan, interface, reload, reload_dirs, reload_includes, reload_excludes, reload_delay, workers, env_file, log_config, log_level, access_log, proxy_headers, server_header, date_header, forwarded_allow_ips, root_path, limit_concurrency, backlog, limit_max_requests, timeout_keep_alive, timeout_graceful_shutdown, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_version, ssl_cert_reqs, ssl_ca_certs, ssl_ciphers, headers, use_colors, app_dir, factory, h11_max_incomplete_event_size)\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0mMultiprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msockets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m             \u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muds\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/uvicorn/server.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, sockets)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msockets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_event_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msockets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msockets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msockets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_future\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_destroy_pending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stopping\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36m_run_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m                     \u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                     \u001b[0;31m# restore the current task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/asyncio/events.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSystemExit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/asyncio/tasks.py\u001b[0m in \u001b[0;36m__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0;31m# instead of `__next__()`, which is slower for futures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;31m# that return non-generator iterators from their `__iter__`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# Needed to break cycles when an exception occurs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/asyncio/tasks.py\u001b[0m in \u001b[0;36m__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0;31m# We use the `send` method directly, because coroutines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0;31m# don't have `__iter__` and `__next__` methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/uvicorn/server.py\u001b[0m in \u001b[0;36mserve\u001b[0;34m(self, sockets)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msockets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture_signals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_serve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msockets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/uvicorn/server.py\u001b[0m in \u001b[0;36mcapture_signals\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;31m# done LIFO, see https://stackoverflow.com/questions/48434964\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcaptured_signal\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_captured_signals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m             \u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_signal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaptured_signal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhandle_exit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFrameType\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "nest_asyncio.apply()\n",
        "uvicorn.run(app, port=8000)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}