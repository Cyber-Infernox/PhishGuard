{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaOIR8Dvq3PO"
      },
      "source": [
        "# **Public Phishing URL Detection model API**\n",
        "\n",
        "*Final project of Machine Learning & Cybersecurity*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62GP1VmlyiDb",
        "outputId": "3e0cb04f-a7cb-4116-b7d0-42b1fa020bcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:132: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1Fre2MrpO6rvT0XAX3u5rhW5FRG-oGPAB\n",
            "From (redirected): https://drive.google.com/uc?id=1Fre2MrpO6rvT0XAX3u5rhW5FRG-oGPAB&confirm=t&uuid=f045f264-6248-46b2-8efe-3a74b00ad1b0\n",
            "To: /content/dataset.sav\n",
            "100% 1.23G/1.23G [00:18<00:00, 68.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "# dataset.sav\n",
        "! gdown --id 1Fre2MrpO6rvT0XAX3u5rhW5FRG-oGPAB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUnS5xHy8NH7",
        "outputId": "0cce5457-72c9-4df1-90e7-d8cfe0b23738"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fastapi\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starlette<0.38.0,>=0.37.2 (from fastapi)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.7.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (4.12.2)\n",
            "Collecting fastapi-cli>=0.0.2 (from fastapi)\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Collecting httpx>=0.23.0 (from fastapi)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2>=2.11.2 in /usr/local/lib/python3.10/dist-packages (from fastapi) (3.1.4)\n",
            "Collecting python-multipart>=0.0.7 (from fastapi)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi)\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson>=3.2.1 (from fastapi)\n",
            "  Downloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi)\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Collecting uvicorn[standard]>=0.12.0 (from fastapi)\n",
            "  Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi) (3.7)\n",
            "Requirement already satisfied: typer>=0.12.3 in /usr/local/lib/python3.10/dist-packages (from fastapi-cli>=0.0.2->fastapi) (0.12.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.23.0->fastapi)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.23.0->fastapi)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.2->fastapi) (2.1.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.18.4)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0->fastapi) (8.1.7)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.12.0->fastapi)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.12.0->fastapi)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0->fastapi) (6.0.1)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.12.0->fastapi)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.12.0->fastapi)\n",
            "  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.12.0->fastapi)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.23.0->fastapi) (1.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (13.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (0.1.2)\n",
            "Installing collected packages: websockets, uvloop, ujson, python-multipart, python-dotenv, orjson, httptools, h11, dnspython, watchfiles, uvicorn, starlette, httpcore, email_validator, httpx, fastapi-cli, fastapi\n",
            "Successfully installed dnspython-2.6.1 email_validator-2.2.0 fastapi-0.111.0 fastapi-cli-0.0.4 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 orjson-3.10.5 python-dotenv-1.0.1 python-multipart-0.0.9 starlette-0.37.2 ujson-5.10.0 uvicorn-0.30.1 uvloop-0.19.0 watchfiles-0.22.0 websockets-12.0\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (0.30.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (4.12.2)\n",
            "Collecting pickle5\n",
            "  Downloading pickle5-0.0.11.tar.gz (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.1/132.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pickle5\n",
            "  Building wheel for pickle5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pickle5: filename=pickle5-0.0.11-cp310-cp310-linux_x86_64.whl size=255318 sha256=f47b16e67b4d467d7b343b005863f9cd709487c946c026da8d9b6b171b917765\n",
            "  Stored in directory: /root/.cache/pip/wheels/7d/14/ef/4aab19d27fa8e58772be5c71c16add0426acf9e1f64353235c\n",
            "Successfully built pickle5\n",
            "Installing collected packages: pickle5\n",
            "Successfully installed pickle5-0.0.11\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (2.7.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic) (4.12.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.6.2)\n",
            "Collecting pypi-json\n",
            "  Downloading pypi_json-0.4.0-py3-none-any.whl (26 kB)\n",
            "Collecting apeye>=1.1.0 (from pypi-json)\n",
            "  Downloading apeye-1.4.1-py3-none-any.whl (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=21.0 in /usr/local/lib/python3.10/dist-packages (from pypi-json) (24.1)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from pypi-json) (2.31.0)\n",
            "Collecting apeye-core>=1.0.0b2 (from apeye>=1.1.0->pypi-json)\n",
            "  Downloading apeye_core-1.1.5-py3-none-any.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.3/99.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting domdf-python-tools>=2.6.0 (from apeye>=1.1.0->pypi-json)\n",
            "  Downloading domdf_python_tools-3.9.0-py3-none-any.whl (127 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.1/127.1 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from apeye>=1.1.0->pypi-json) (4.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->pypi-json) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->pypi-json) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->pypi-json) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->pypi-json) (2024.6.2)\n",
            "Requirement already satisfied: natsort>=7.0.1 in /usr/local/lib/python3.10/dist-packages (from domdf-python-tools>=2.6.0->apeye>=1.1.0->pypi-json) (8.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.10/dist-packages (from domdf-python-tools>=2.6.0->apeye>=1.1.0->pypi-json) (4.12.2)\n",
            "Installing collected packages: domdf-python-tools, apeye-core, apeye, pypi-json\n",
            "Successfully installed apeye-1.4.1 apeye-core-1.1.5 domdf-python-tools-3.9.0 pypi-json-0.4.0\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.1.6-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.1.6\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Collecting pymongo\n",
            "  Downloading pymongo-4.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo) (2.6.1)\n",
            "Installing collected packages: pymongo\n",
            "Successfully installed pymongo-4.8.0\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Collecting python-whois\n",
            "  Downloading python_whois-0.9.4-py3-none-any.whl (103 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from python-whois) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->python-whois) (1.16.0)\n",
            "Installing collected packages: python-whois\n",
            "Successfully installed python-whois-0.9.4\n",
            "Collecting sockets\n",
            "  Downloading sockets-1.0.0-py3-none-any.whl (4.5 kB)\n",
            "Installing collected packages: sockets\n",
            "Successfully installed sockets-1.0.0\n",
            "Collecting tldextract\n",
            "  Downloading tldextract-5.1.2-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.6/97.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from tldextract) (3.7)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from tldextract) (2.31.0)\n",
            "Collecting requests-file>=1.4 (from tldextract)\n",
            "  Downloading requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from tldextract) (3.15.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->tldextract) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->tldextract) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->tldextract) (2024.6.2)\n",
            "Installing collected packages: requests-file, tldextract\n",
            "Successfully installed requests-file-2.1.0 tldextract-5.1.2\n",
            "Collecting tld\n",
            "  Downloading tld-0.13-py2.py3-none-any.whl (263 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.8/263.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tld\n",
            "Successfully installed tld-0.13\n"
          ]
        }
      ],
      "source": [
        "!pip install fastapi\n",
        "!pip install uvicorn\n",
        "!pip install pickle5\n",
        "!pip install pydantic\n",
        "!pip install scikit-learn\n",
        "!pip install requests\n",
        "!pip install pypi-json\n",
        "!pip install pyngrok\n",
        "!pip install nest-asyncio\n",
        "!pip install pymongo\n",
        "!pip install python-dotenv\n",
        "!pip install python-whois\n",
        "!pip install sockets\n",
        "!pip install tldextract\n",
        "!pip install tld"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KE0pNNBX9u5n"
      },
      "outputs": [],
      "source": [
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "import pickle\n",
        "import json\n",
        "import uvicorn\n",
        "from pyngrok import ngrok\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "import nest_asyncio\n",
        "import datetime\n",
        "import ipaddress\n",
        "import re\n",
        "from googlesearch import search\n",
        "import requests\n",
        "import whois\n",
        "import ssl\n",
        "import socket\n",
        "import urllib.parse\n",
        "import tldextract\n",
        "import numpy as np\n",
        "import os\n",
        "from tld import get_tld\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "from starlette.middleware.cors import CORSMiddleware"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Z5A2tDL0Buo8"
      },
      "outputs": [],
      "source": [
        "def get_url_length(url):\n",
        "    return len(url)\n",
        "\n",
        "def get_domain_length(url):\n",
        "    parsed_url = urlparse(url)\n",
        "    domain = parsed_url.netloc\n",
        "    domain_length = len(domain)\n",
        "    return domain_length\n",
        "\n",
        "def is_domain_ip(url):\n",
        "    try:\n",
        "        parsed_url = urlparse(url)\n",
        "        domain = parsed_url.netloc  # Extract the domain part from the URL\n",
        "        ipaddress.ip_address(domain)  # Check if the domain is a valid IP address\n",
        "        return 1\n",
        "    except ValueError:\n",
        "        return 0\n",
        "\n",
        "def tld_length(tld):\n",
        "    if tld:\n",
        "        return len(tld)\n",
        "    else:\n",
        "        return -1\n",
        "\n",
        "def char_continuation_rate(url):\n",
        "    continuous_count = 0\n",
        "    total_count = len(url)\n",
        "\n",
        "    for i in range(1, len(url)):\n",
        "        if url[i] == url[i - 1]:\n",
        "            continuous_count += 1\n",
        "\n",
        "    if total_count > 0:\n",
        "        continuation_rate = continuous_count / total_count\n",
        "    else:\n",
        "        continuation_rate = 0.0\n",
        "\n",
        "    return continuation_rate\n",
        "\n",
        "def url_character_prob(url):\n",
        "    char_count = {}\n",
        "    total_chars = len(url)\n",
        "\n",
        "    for char in url:\n",
        "        char_count[char] = char_count.get(char, 0) + 1\n",
        "\n",
        "    char_prob = {char: count / total_chars for char, count in char_count.items()}\n",
        "\n",
        "    # Calculate the mean probability\n",
        "    mean_prob = sum(char_prob.values()) / len(char_prob)\n",
        "\n",
        "    return mean_prob\n",
        "\n",
        "def number_of_subdomains(url):\n",
        "    parsed_url = urlparse(url)\n",
        "    domain = parsed_url.netloc\n",
        "\n",
        "    if domain:\n",
        "        num_subdomains = domain.count('.')\n",
        "    else:\n",
        "        num_subdomains = 0\n",
        "\n",
        "    return num_subdomains\n",
        "\n",
        "def has_obfuscation(url):\n",
        "    # List of common obfuscation patterns to detect\n",
        "    obfuscation_patterns = [\n",
        "        '%',                     # Percentage encoding\n",
        "        '\\\\x',                   # Hexadecimal encoding\n",
        "        '&#',                    # HTML entity encoding\n",
        "        '\\\\u',                   # Unicode encoding (corrected)\n",
        "        'javascript:',           # JavaScript code injection\n",
        "        'data:',                 # Data URL scheme\n",
        "        'blob:',                 # Blob URL scheme\n",
        "        'onerror', 'onload',     # Event handlers\n",
        "        'document.cookie',       # Access to cookies\n",
        "        'eval(', 'exec(',        # Evaluation functions\n",
        "        'unescape(',             # Unescaping\n",
        "        'String.fromCharCode(', # Constructing strings\n",
        "        'String.fromCodePoint(', # Constructing strings\n",
        "        'String.raw(',           # Constructing strings\n",
        "    ]\n",
        "\n",
        "    # Check if any obfuscation pattern is found in the URL\n",
        "    for pattern in obfuscation_patterns:\n",
        "        if pattern in url.lower():\n",
        "            return 1  # Obfuscation detected\n",
        "\n",
        "    return 0  # No obfuscation detected\n",
        "\n",
        "def number_of_obfuscated_chars(url):\n",
        "    # List of common obfuscation patterns to detect\n",
        "    obfuscation_patterns = [\n",
        "        '%',     # Percentage encoding\n",
        "        '&#',    # HTML entity encoding\n",
        "        '\\\\u',   # Unicode encoding\n",
        "        '\\\\x',   # Hexadecimal encoding\n",
        "        '\\u202E', '\\u200E', '\\u200F', '\\u202A', '\\u202B', '\\u202C'  # Directional formatting characters\n",
        "    ]\n",
        "\n",
        "    # Initialize the counter for obfuscated characters\n",
        "    num_obfuscated_chars = 0\n",
        "\n",
        "    # Check for each obfuscation pattern in the URL\n",
        "    for pattern in obfuscation_patterns:\n",
        "        # Count the occurrences of the obfuscation pattern in the URL\n",
        "        num_obfuscated_chars += url.lower().count(pattern)\n",
        "\n",
        "    return num_obfuscated_chars\n",
        "\n",
        "def obfuscation_ratio(url):\n",
        "    # List of common obfuscation patterns to detect\n",
        "    obfuscation_patterns = [\n",
        "        '%',     # Percentage encoding\n",
        "        '&#',    # HTML entity encoding\n",
        "        '\\\\u',   # Unicode encoding\n",
        "        '\\\\x',   # Hexadecimal encoding\n",
        "        '\\u202E', '\\u200E', '\\u200F', '\\u202A', '\\u202B', '\\u202C'  # Directional formatting characters\n",
        "    ]\n",
        "\n",
        "    # Count the total number of characters in the URL\n",
        "    total_chars = len(url)\n",
        "\n",
        "    # Initialize the counter for obfuscated characters\n",
        "    num_obfuscated_chars = 0\n",
        "\n",
        "    # Check for each obfuscation pattern in the URL\n",
        "    for pattern in obfuscation_patterns:\n",
        "        # Count the occurrences of the obfuscation pattern in the URL\n",
        "        num_obfuscated_chars += url.lower().count(pattern)\n",
        "\n",
        "    # Calculate the obfuscation ratio\n",
        "    obfuscation_ratio = num_obfuscated_chars / total_chars if total_chars > 0 else 0.0\n",
        "\n",
        "    return obfuscation_ratio\n",
        "\n",
        "def number_of_letters_in_url(url):\n",
        "    letters = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "\n",
        "    num_letters = sum(url.count(letter) for letter in letters)\n",
        "\n",
        "    return num_letters\n",
        "\n",
        "def letter_ratio_in_url(url):\n",
        "    num_letters = number_of_letters_in_url(url)\n",
        "\n",
        "    total_chars = len(url)\n",
        "\n",
        "    if total_chars > 0:\n",
        "        letter_ratio = num_letters / total_chars\n",
        "    else:\n",
        "        letter_ratio = 0.0\n",
        "\n",
        "    return letter_ratio\n",
        "\n",
        "def number_of_digits_in_url(url):\n",
        "    digits = '0123456789'\n",
        "\n",
        "    num_digits = sum(url.count(digit) for digit in digits)\n",
        "\n",
        "    return num_digits\n",
        "\n",
        "def digit_ratio_in_url(url):\n",
        "    num_digits = number_of_digits_in_url(url)\n",
        "\n",
        "    total_chars = len(url)\n",
        "\n",
        "    if total_chars > 0:\n",
        "        digit_ratio = num_digits / total_chars\n",
        "    else:\n",
        "        digit_ratio = 0.0\n",
        "\n",
        "    return digit_ratio\n",
        "\n",
        "def number_of_ampersand_in_url(url):\n",
        "    num_ampersand = url.count('&')\n",
        "\n",
        "    return num_ampersand\n",
        "\n",
        "def number_of_other_special_chars_in_url(url):\n",
        "    allowed_chars = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789./:?&=%'\n",
        "\n",
        "    num_other_special_chars = sum(1 for char in url if char not in allowed_chars)\n",
        "\n",
        "    return num_other_special_chars\n",
        "\n",
        "def special_char_ratio_in_url(url):\n",
        "    num_special_chars = number_of_other_special_chars_in_url(url)\n",
        "\n",
        "    total_chars = len(url)\n",
        "\n",
        "    if total_chars > 0:\n",
        "        special_char_ratio = num_special_chars / total_chars\n",
        "    else:\n",
        "        special_char_ratio = 0.0\n",
        "\n",
        "    return special_char_ratio\n",
        "\n",
        "def is_https(url):\n",
        "    # Check if the URL starts with \"https://\"\n",
        "    if url.startswith(\"https://\"):\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def calculate_tld_legitimate_prop(url):\n",
        "    try:\n",
        "        # Get the Top-Level Domain (TLD) from the URL\n",
        "        tld = get_tld(url, fail_silently=True)\n",
        "\n",
        "        # List of commonly recognized TLDs used by legitimate websites\n",
        "        legitimate_tlds = ['com', 'net', 'org', 'edu', 'gov']\n",
        "\n",
        "        # Check if the extracted TLD is in the list of legitimate TLDs\n",
        "        if tld in legitimate_tlds:\n",
        "            return 1.0  # TLD is considered legitimate\n",
        "        else:\n",
        "            return 0.0  # TLD is not considered legitimate\n",
        "    except:\n",
        "        return -1  # Error: Unable to extract TLD\n",
        "\n",
        "#Use of IP or not in domain\n",
        "def having_ip_address(url):\n",
        "    match = re.search(\n",
        "        '(([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.'\n",
        "        '([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\/)|'  # IPv4\n",
        "        '((0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\/)' # IPv4 in hexadecimal\n",
        "        '(?:[a-fA-F0-9]{1,4}:){7}[a-fA-F0-9]{1,4}', url)  # Ipv6\n",
        "    if match:\n",
        "        # print match.group()\n",
        "        return 1\n",
        "    else:\n",
        "        # print 'No matching pattern found'\n",
        "        return 0\n",
        "\n",
        "def abnormal_url(url):\n",
        "    hostname = urlparse(url).hostname\n",
        "    hostname = str(hostname)\n",
        "    match = re.search(hostname, url)\n",
        "    if match:\n",
        "        # print match.group()\n",
        "        return 1\n",
        "    else:\n",
        "        # print 'No matching pattern found'\n",
        "        return 0\n",
        "\n",
        "def count_per(url):\n",
        "    return url.count('%')\n",
        "\n",
        "def count_ques(url):\n",
        "    return url.count('?')\n",
        "\n",
        "def count_hyphen(url):\n",
        "    return url.count('-')\n",
        "\n",
        "def count_equal(url):\n",
        "    return url.count('=')\n",
        "\n",
        "def count_www(url):\n",
        "  url.count('www')\n",
        "  return url.count('www')\n",
        "\n",
        "def count_atrate(url):\n",
        "  return url.count('@')\n",
        "\n",
        "def no_of_dir(url):\n",
        "  urldir = urlparse(url).path\n",
        "  return urldir.count('/')\n",
        "\n",
        "def no_of_embed(url):\n",
        "  urldir = urlparse(url).path\n",
        "  return urldir.count('//')\n",
        "\n",
        "def count_https(url):\n",
        "    return url.count('https')\n",
        "\n",
        "def count_http(url):\n",
        "    return url.count('http')\n",
        "\n",
        "def count_dot(url):\n",
        "  count_dot = url.count('.')\n",
        "  return count_dot\n",
        "\n",
        "def shortening_service(url):\n",
        "    match = re.search('bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|'\n",
        "                      'yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|'\n",
        "                      'short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|'\n",
        "                      'doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|'\n",
        "                      'db\\.tt|qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|'\n",
        "                      'q\\.gs|is\\.gd|po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|'\n",
        "                      'x\\.co|prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|'\n",
        "                      'tr\\.im|link\\.zip\\.net',\n",
        "                      url)\n",
        "    if match:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def hostname_length(url):\n",
        "    return len(urlparse(url).netloc)\n",
        "\n",
        "def suspicious_words(url):\n",
        "    match = re.search('PayPal|login|signin|bank|account|update|free|lucky|service|bonus|ebayisapi|webscr',\n",
        "                      url)\n",
        "    if match:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def digit_count(url):\n",
        "    digits = 0\n",
        "    for i in url:\n",
        "        if i.isnumeric():\n",
        "            digits = digits + 1\n",
        "    return digits\n",
        "\n",
        "def letter_count(url):\n",
        "    letters = 0\n",
        "    for i in url:\n",
        "        if i.isalpha():\n",
        "            letters = letters + 1\n",
        "    return letters\n",
        "\n",
        "def google_index(url):\n",
        "  site = search(url, 5)\n",
        "  return 1 if site else 0\n",
        "\n",
        "def fd_length(url):\n",
        "    urlpath= urlparse(url).path\n",
        "    try:\n",
        "        return len(urlpath.split('/')[1])\n",
        "    except:\n",
        "        return 0\n",
        "\n",
        "# Request functions\n",
        "\n",
        "# Function to check if the URL is accessible\n",
        "def check_url_access(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        return 1  # Return 1 if the URL is accessible\n",
        "    except requests.exceptions.RequestException:\n",
        "        return 0  # Return 0 if there's an error accessing the URL\n",
        "\n",
        "# Function to check if the URL is redirected\n",
        "def check_redirect(url):\n",
        "    try:\n",
        "        response = requests.get(url, allow_redirects=False)\n",
        "        if response.status_code == 301 or response.status_code == 302:\n",
        "            return 0  # Return 0 if the URL is redirected\n",
        "        else:\n",
        "            return 1  # Return 1 if the URL is not redirected\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error accessing {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Function to send an HTTP request to the given URL and retrieve the response\n",
        "def send_http_request(url):\n",
        "    try:\n",
        "        response = requests.get(url, timeout=10)  # Set a timeout for the request\n",
        "        if response.status_code == 200:\n",
        "            return 1 if not analyze_content(response) else 0\n",
        "        else:\n",
        "            print(f\"Error accessing {url}: Status code {response.status_code}\")\n",
        "            return None\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error accessing {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Function to analyze the content of the response for phishing indicators\n",
        "def analyze_content(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        if response.status_code == 200:\n",
        "            content = response.text\n",
        "            # Implement content analysis logic here\n",
        "            # Example: Check for presence of known phishing keywords or patterns\n",
        "            phishing_keywords = ['login', 'password', 'bank', 'secure']\n",
        "            for keyword in phishing_keywords:\n",
        "                if re.search(keyword, content, re.IGNORECASE):\n",
        "                    return 0  # Phishing indicator found\n",
        "            return 1  # No phishing indicator found\n",
        "        else:\n",
        "            print(f\"Error: Unable to fetch content from {url}. Status code: {response.status_code}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error analyzing content for {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "def verify_ssl_certificate(url):\n",
        "    try:\n",
        "        context = ssl.create_default_context()\n",
        "        with socket.create_connection((url, 443)) as sock:\n",
        "            with context.wrap_socket(sock, server_hostname=url) as ssock:\n",
        "                cert = ssock.getpeercert()\n",
        "                if cert:\n",
        "                    # Check if the certificate is valid and issued by a trusted CA\n",
        "                    if ssl.match_hostname(cert, url):\n",
        "                        # Check if the certificate is not expired\n",
        "                        cert_not_after = datetime.datetime.strptime(cert['notAfter'], \"%b %d %H:%M:%S %Y %Z\")\n",
        "                        if cert_not_after > datetime.datetime.now():\n",
        "                            return 1  # Valid SSL certificate\n",
        "                        else:\n",
        "                            return 0  # Expired SSL certificate\n",
        "                    else:\n",
        "                        return 0  # Certificate does not match hostname\n",
        "                else:\n",
        "                    return 0  # No certificate available\n",
        "    except Exception as e:\n",
        "        print(f\"Error verifying SSL certificate for {url}: {e}\")\n",
        "        return None  # Error occurred\n",
        "\n",
        "def query_whois(url):\n",
        "    try:\n",
        "        # Extract domain from the URL\n",
        "        parsed_url = urlparse(url)\n",
        "        domain = parsed_url.netloc\n",
        "\n",
        "        # Perform WHOIS query for the extracted domain\n",
        "        w = whois.whois(domain)\n",
        "\n",
        "        if w:\n",
        "            # Check if WHOIS information indicates the domain is legitimate\n",
        "            # Note: WHOIS information alone might not be sufficient for a definitive conclusion\n",
        "            if 'creation_date' in w and 'expiration_date' in w:\n",
        "                return 1  # Legitimate domain\n",
        "            else:\n",
        "                return 0  # Suspicious domain\n",
        "        else:\n",
        "            return 0  # Suspicious domain\n",
        "    except Exception as e:\n",
        "        # Handle any errors that occur during the WHOIS query\n",
        "        print(f\"Error querying WHOIS information for {domain}: {e}\")\n",
        "        return 0  # Suspicious domain due to error\n",
        "\n",
        "def check_domain_reputation(url):\n",
        "    # Extract domain from the URL\n",
        "    parsed_url = urlparse(url)\n",
        "    domain = parsed_url.netloc\n",
        "\n",
        "    # Example: Using a hypothetical API for domain reputation check\n",
        "    api_url = \"https://example.com/domain-reputation-api\"\n",
        "    payload = {'domain': domain}\n",
        "\n",
        "    try:\n",
        "        response = requests.get(api_url, params=payload)\n",
        "        if response.status_code == 200:\n",
        "            result = response.json()\n",
        "            if result['blacklisted']:\n",
        "                return 0  # Domain is blacklisted\n",
        "            else:\n",
        "                return 1  # Domain is not blacklisted\n",
        "        else:\n",
        "            # API request failed, return an error code or handle the error as needed\n",
        "            return -1  # Error occurred\n",
        "    except Exception as e:\n",
        "        # Handle exceptions such as network errors\n",
        "        print(\"Exception occurred:\", e)\n",
        "        return -1  # Error occurred\n",
        "\n",
        "def check_url_blacklist(url):\n",
        "    # Example: Using a hypothetical API for URL blacklist check\n",
        "    api_url = \"https://example.com/blacklist-api\"\n",
        "    payload = {'url': url}\n",
        "    try:\n",
        "        response = requests.get(api_url, params=payload)\n",
        "        if response.status_code == 200:\n",
        "            result = response.json()\n",
        "            if result['blacklisted']:\n",
        "                return 0  # Phishing URL\n",
        "            else:\n",
        "                return 1  # Safe URL\n",
        "        else:\n",
        "            # API request failed, return an error code or handle the error as needed\n",
        "            return -1  # Error occurred\n",
        "    except Exception as e:\n",
        "        # Handle exceptions such as network errors\n",
        "        print(\"Exception occurred:\", e)\n",
        "        return -1  # Error occurred\n",
        "\n",
        "# Function to analyze the IP address associated with the URL\n",
        "def analyze_ip_address(url):\n",
        "    try:\n",
        "        # Extract domain from the URL\n",
        "        domain = urllib.parse.urlparse(url).netloc\n",
        "\n",
        "        # Get the IP address associated with the domain\n",
        "        ip_address = socket.gethostbyname(domain)\n",
        "\n",
        "        # Check the IP address against threat intelligence sources\n",
        "        if check_blacklist(ip_address):\n",
        "            return 1  # Malicious IP address\n",
        "        else:\n",
        "            return 0  # Clean IP address\n",
        "    except Exception as e:\n",
        "        print(f\"Error analyzing IP address for {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "def check_blacklist(ip_address):\n",
        "    # Example: Check against a public blacklist\n",
        "    blacklist_url = f\"https://www.abuseipdb.com/check/{ip_address}\"\n",
        "    try:\n",
        "        response = requests.get(blacklist_url)\n",
        "        if response.status_code == 200:\n",
        "            # Check if the IP address is listed in the blacklist\n",
        "            if \"This IP address has been reported\" in response.text:\n",
        "                return True\n",
        "            else:\n",
        "                return False\n",
        "        else:\n",
        "            print(f\"Error checking blacklist for {ip_address}: Status code {response.status_code}\")\n",
        "            return False\n",
        "    except Exception as e:\n",
        "        print(f\"Error checking blacklist for {ip_address}: {e}\")\n",
        "        return False\n",
        "\n",
        "# Function to handle different user-agent strings to evade detection\n",
        "def spoof_user_agent(url):\n",
        "    try:\n",
        "        custom_user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.9999.99 Safari/537.36\"\n",
        "        headers = {\n",
        "            'User-Agent': custom_user_agent\n",
        "        }\n",
        "        response = requests.get(url, headers=headers, timeout=10)  # Set a timeout for the request\n",
        "        if response.status_code == 200:\n",
        "            return 1 if not analyze_content(response) else 0\n",
        "        else:\n",
        "            print(f\"Error accessing {url}: Status code {response.status_code}\")\n",
        "            return None\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error accessing {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Function to handle sessions and cookies\n",
        "def handle_sessions(url):\n",
        "    session = requests.Session()\n",
        "    try:\n",
        "        response = session.get(url, timeout=10)  # Set a timeout for the request\n",
        "        if response.status_code == 200:\n",
        "            return 1 if not analyze_content(response) else 0\n",
        "        else:\n",
        "            print(f\"Error accessing {url}: Status code {response.status_code}\")\n",
        "            return None\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error accessing {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Function to handle request timeouts\n",
        "def handle_request_timeout(url, timeout=5):\n",
        "    try:\n",
        "        response = requests.get(url, timeout=timeout)\n",
        "        if response.status_code == 200:\n",
        "            return 1 if not analyze_content(response) else 0\n",
        "        else:\n",
        "            print(f\"Error accessing {url}: Status code {response.status_code}\")\n",
        "            return None\n",
        "    except requests.exceptions.Timeout:\n",
        "        print(f\"Timeout accessing {url}\")\n",
        "        return 0  # Treat as clean (no phishing indicators) due to timeout\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error accessing {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Function to perform more advanced checks based on TLD and subdomain\n",
        "def advanced_url_analysis(url):\n",
        "    try:\n",
        "        # Extract domain and subdomain information from the URL\n",
        "        extracted = tldextract.extract(url)\n",
        "        domain = extracted.domain\n",
        "        subdomain = extracted.subdomain\n",
        "\n",
        "        # Check if the domain or subdomain contains known malicious patterns\n",
        "        if check_malicious_pattern(domain) or check_malicious_pattern(subdomain):\n",
        "            return 0  # Phishing indicator found\n",
        "        else:\n",
        "            # Query WHOIS information for the domain\n",
        "            if query_whois(domain):\n",
        "                return 1  # Legitimate domain\n",
        "            else:\n",
        "                return 0  # Phishing indicator found\n",
        "    except Exception as e:\n",
        "        print(f\"Error performing advanced URL analysis for {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "def check_malicious_pattern(text):\n",
        "    # Implement logic to check for known malicious patterns in text\n",
        "    malicious_patterns = ['paypal', 'security', 'login', 'bank', 'phish']\n",
        "    for pattern in malicious_patterns:\n",
        "        if pattern in text.lower():\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def query_whois(domain):\n",
        "    try:\n",
        "        w = whois.whois(domain)\n",
        "        if w:\n",
        "            # Check if WHOIS information indicates the domain is legitimate\n",
        "            if 'creation_date' in w and 'expiration_date' in w:\n",
        "                return True\n",
        "            else:\n",
        "                return False\n",
        "        else:\n",
        "            return False\n",
        "    except Exception as e:\n",
        "        print(f\"Error querying WHOIS information for {domain}: {e}\")\n",
        "        return False\n",
        "\n",
        "def get_main_website_url(long_url):\n",
        "    # Parse the URL to extract its components\n",
        "    parsed_url = urlparse(long_url)\n",
        "\n",
        "    # Construct the main website URL\n",
        "    main_website_url = f\"{parsed_url.scheme}://{parsed_url.netloc}/\"\n",
        "\n",
        "    return main_website_url\n",
        "\n",
        "def mainly(url):\n",
        "\n",
        "    status = []\n",
        "\n",
        "    status.append(get_url_length(url))\n",
        "    status.append(get_domain_length(url))\n",
        "    status.append(is_domain_ip(url))\n",
        "    tld = get_tld(url,fail_silently=True)\n",
        "    status.append(tld_length(tld))\n",
        "    status.append(char_continuation_rate(url))\n",
        "    status.append(url_character_prob(url))\n",
        "    status.append(number_of_subdomains(url))\n",
        "    status.append(has_obfuscation(url))\n",
        "    status.append(number_of_obfuscated_chars(url))\n",
        "    status.append(obfuscation_ratio(url))\n",
        "    status.append(number_of_letters_in_url(url))\n",
        "    status.append(letter_ratio_in_url(url))\n",
        "    status.append(number_of_digits_in_url(url))\n",
        "    status.append(digit_ratio_in_url(url))\n",
        "    status.append(number_of_ampersand_in_url(url))\n",
        "    status.append(number_of_other_special_chars_in_url(url))\n",
        "    status.append(special_char_ratio_in_url(url))\n",
        "    status.append(is_https(url))\n",
        "    status.append(calculate_tld_legitimate_prop(url))\n",
        "    status.append(having_ip_address(url))\n",
        "    status.append(abnormal_url(url))\n",
        "    status.append(count_per(url))\n",
        "    status.append(count_ques(url))\n",
        "    status.append(count_hyphen(url))\n",
        "    status.append(count_equal(url))\n",
        "    status.append(count_www(url))\n",
        "    status.append(count_atrate(url))\n",
        "    status.append(no_of_dir(url))\n",
        "    status.append(no_of_embed(url))\n",
        "    status.append(count_https(url))\n",
        "    status.append(count_dot(url))\n",
        "    status.append(count_http(url))\n",
        "    status.append(shortening_service(url))\n",
        "    status.append(hostname_length(url))\n",
        "    status.append(suspicious_words(url))\n",
        "    status.append(digit_count(url))\n",
        "    status.append(letter_count(url))\n",
        "    status.append(google_index(url))\n",
        "    status.append(fd_length(url))\n",
        "\n",
        "    return status\n",
        "\n",
        "def get_prediction_from_url(test_url):\n",
        "\n",
        "    if(check_url_access(test_url) == 0):\n",
        "        return \"PHISHING\"\n",
        "\n",
        "    if(check_url_blacklist(test_url) == 0):\n",
        "        return \"PHISHING\"\n",
        "\n",
        "    if(verify_ssl_certificate(test_url) == 0):\n",
        "        return \"PHISHING\"\n",
        "\n",
        "    if(send_http_request(test_url) == 0):\n",
        "        return \"PHISHING\"\n",
        "\n",
        "    if(check_domain_reputation(test_url) == 0):\n",
        "        return \"PHISHING\"\n",
        "\n",
        "    if(spoof_user_agent(test_url) == 0):\n",
        "        return \"PHISHING\"\n",
        "\n",
        "    if(handle_sessions(test_url) == 0):\n",
        "        return \"PHISHING\"\n",
        "\n",
        "    if(handle_request_timeout(test_url, timeout=5) == 0):\n",
        "        return \"PHISHING\"\n",
        "\n",
        "    if(advanced_url_analysis(test_url) == 0):\n",
        "        return \"PHISHING\"\n",
        "\n",
        "    #if(analyze_ip_address(test_url) == 0):\n",
        "        #return \"PHISHING\"\n",
        "\n",
        "    #if(query_whois(test_url) == 0):\n",
        "        #return \"PHISHING\"\n",
        "\n",
        "    #if(analyze_content(test_url) == 0):\n",
        "        #return \"PHISHING\"\n",
        "\n",
        "    test_url = get_main_website_url(test_url)\n",
        "\n",
        "    features_test = mainly(test_url)\n",
        "\n",
        "    # Due to updates to scikit-learn, we now need a 2D array as a parameter to the predict function.\n",
        "    features_test = np.array(features_test).reshape((1, -1))\n",
        "\n",
        "    pred = loaded_model.predict(features_test)\n",
        "\n",
        "    return pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "t9Uqoplr-ES3"
      },
      "outputs": [],
      "source": [
        "app = FastAPI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BQCwDg5M-GYk"
      },
      "outputs": [],
      "source": [
        "# Allow all origins, all methods, and all headers\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],  # Allow any origin\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],  # Allow all HTTP methods\n",
        "    allow_headers=[\"*\"],  # Allow all headers\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "m4_isbg1-LoI"
      },
      "outputs": [],
      "source": [
        "class model_input(BaseModel):\n",
        "    url : str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YjtwemIBAocg"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "\n",
        "from pymongo import MongoClient\n",
        "# from dotenv import load_dotenv\n",
        "\n",
        "# load_dotenv(\".env\")\n",
        "\n",
        "MONGO_URI = \"mongodb+srv://sayonkar:megacity@phishguard.x6swwrr.mongodb.net/?retryWrites=true&w=majority&appName=PhishGuard\"\n",
        "MONGO_PREDICT_DB = \"dataset\"\n",
        "MONGO_PREDICT_COLLECTION = \"urls\"\n",
        "\n",
        "# Connect to MongoDB\n",
        "try:\n",
        "    client = MongoClient(MONGO_URI)\n",
        "    db = client[MONGO_PREDICT_DB]\n",
        "    collection = db[MONGO_PREDICT_COLLECTION]\n",
        "    connection_status = True\n",
        "except Exception as e:\n",
        "    connection_status = False\n",
        "\n",
        "# Function to check if URL exists in the database and return its type\n",
        "def check_url_type(url):\n",
        "    if not connection_status:\n",
        "        return False\n",
        "\n",
        "    result = collection.find_one({\"url\": url})\n",
        "    if result:\n",
        "        return result[\"type\"]\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def add_url_to_database(url, url_type):\n",
        "    if not connection_status:\n",
        "        return False\n",
        "\n",
        "    try:\n",
        "        collection.insert_one({\"url\": url, \"type\": url_type})\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TxPT5r75-fap"
      },
      "outputs": [],
      "source": [
        "# loading the saved model\n",
        "loaded_model = pickle.load(open('/content/dataset.sav','rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cBwGCNRx_KO0"
      },
      "outputs": [],
      "source": [
        "@app.post('/url_prediction')\n",
        "def url_pred(input_parameters : model_input):\n",
        "    input_data = input_parameters.json()\n",
        "    input_dictionary = json.loads(input_data)\n",
        "\n",
        "    url = input_dictionary['url']\n",
        "\n",
        "    input_list = [url]\n",
        "\n",
        "    url_type = check_url_type(url)\n",
        "    if url_type:\n",
        "        if url_type == \"benign\":\n",
        "          return f\"SAFE\"\n",
        "        else:\n",
        "          return f\"PHISHING\"\n",
        "    else:\n",
        "        prediction = get_prediction_from_url(url)\n",
        "\n",
        "        if prediction[0] == 0:\n",
        "            diagnosis = \"benign\"\n",
        "\n",
        "        elif prediction[0] == 1:\n",
        "            diagnosis = \"phishing\"\n",
        "\n",
        "        # Add URL and its type to the database\n",
        "        if add_url_to_database(url, diagnosis):\n",
        "            return diagnosis\n",
        "        else:\n",
        "            return \"Failure\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzprK7q5GNLA",
        "outputId": "a0872baa-8230-4666-b0db-e96aac0b7f31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken 2fRwWS2qV8fmdyBPkzohLCdwBXt_6xSeFsiPkbrwJF5Z938ur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vy-i3x90A63n",
        "outputId": "ca186629-9aa3-4eb0-a50d-d5e751b088fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: https://39e7-34-106-17-90.ngrok-free.app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [328]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     2405:201:8004:78ff:39da:b5c4:dba4:ac63:0 - \"POST /url_prediction HTTP/1.1\" 500 Internal Server Error\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:    Exception in ASGI application\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/uvicorn/protocols/http/httptools_impl.py\", line 399, in run_asgi\n",
            "    result = await app(  # type: ignore[func-returns-value]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/uvicorn/middleware/proxy_headers.py\", line 70, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fastapi/applications.py\", line 1054, in __call__\n",
            "    await super().__call__(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/starlette/applications.py\", line 123, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/starlette/middleware/errors.py\", line 186, in __call__\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/starlette/middleware/errors.py\", line 164, in __call__\n",
            "    await self.app(scope, receive, _send)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/starlette/middleware/cors.py\", line 85, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/starlette/middleware/exceptions.py\", line 65, in __call__\n",
            "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/starlette/_exception_handler.py\", line 64, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/starlette/routing.py\", line 756, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/starlette/routing.py\", line 776, in app\n",
            "    await route.handle(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/starlette/routing.py\", line 297, in handle\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/starlette/routing.py\", line 77, in app\n",
            "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/starlette/_exception_handler.py\", line 64, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/starlette/routing.py\", line 72, in app\n",
            "    response = await func(request)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fastapi/routing.py\", line 278, in app\n",
            "    raw_response = await run_endpoint_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fastapi/routing.py\", line 193, in run_endpoint_function\n",
            "    return await run_in_threadpool(dependant.call, **values)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/starlette/concurrency.py\", line 42, in run_in_threadpool\n",
            "    return await anyio.to_thread.run_sync(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/lib/python3.10/asyncio/futures.py\", line 285, in __await__\n",
            "    yield self  # This tells Task to wait for completion.\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 304, in __wakeup\n",
            "    future.result()\n",
            "  File \"/usr/lib/python3.10/asyncio/futures.py\", line 201, in result\n",
            "    raise self._exception.with_traceback(self._exception_tb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"<ipython-input-10-aa0cf2b923a5>\", line 26, in url_pred\n",
            "    if add_url_to_database(url, diagnosis):\n",
            "UnboundLocalError: local variable 'diagnosis' referenced before assignment\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error verifying SSL certificate for https://www.chess.com/: [Errno -2] Name or service not known\n",
            "Error analyzing content for <Response [200]>: Failed to parse: <Response [200]>\n",
            "Error analyzing content for <Response [200]>: Failed to parse: <Response [200]>\n",
            "Error analyzing content for <Response [200]>: Failed to parse: <Response [200]>\n",
            "Error analyzing content for <Response [200]>: Failed to parse: <Response [200]>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     2405:201:8004:78ff:39da:b5c4:dba4:ac63:0 - \"POST /url_prediction HTTP/1.1\" 200 OK\n",
            "Error verifying SSL certificate for http://www.mnnit.ac.in/: [Errno -2] Name or service not known\n",
            "Error analyzing content for <Response [200]>: Failed to parse: <Response [200]>\n",
            "Error analyzing content for <Response [200]>: Failed to parse: <Response [200]>\n",
            "Error analyzing content for <Response [200]>: Failed to parse: <Response [200]>\n",
            "Error analyzing content for <Response [200]>: Failed to parse: <Response [200]>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     2405:201:8004:78ff:39da:b5c4:dba4:ac63:0 - \"POST /url_prediction HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [328]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-a1a31a32c385>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Public URL:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngrok_tunnel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublic_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnest_asyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0muvicorn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/uvicorn/main.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(app, host, port, uds, fd, loop, http, ws, ws_max_size, ws_max_queue, ws_ping_interval, ws_ping_timeout, ws_per_message_deflate, lifespan, interface, reload, reload_dirs, reload_includes, reload_excludes, reload_delay, workers, env_file, log_config, log_level, access_log, proxy_headers, server_header, date_header, forwarded_allow_ips, root_path, limit_concurrency, backlog, limit_max_requests, timeout_keep_alive, timeout_graceful_shutdown, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_version, ssl_cert_reqs, ssl_ca_certs, ssl_ciphers, headers, use_colors, app_dir, factory, h11_max_incomplete_event_size)\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0mMultiprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msockets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m             \u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muds\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/uvicorn/server.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, sockets)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msockets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_event_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msockets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msockets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msockets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_future\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_destroy_pending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stopping\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36m_run_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m                     \u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                     \u001b[0;31m# restore the current task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/asyncio/events.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSystemExit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/asyncio/tasks.py\u001b[0m in \u001b[0;36m__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0;31m# instead of `__next__()`, which is slower for futures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;31m# that return non-generator iterators from their `__iter__`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# Needed to break cycles when an exception occurs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/asyncio/tasks.py\u001b[0m in \u001b[0;36m__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0;31m# We use the `send` method directly, because coroutines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0;31m# don't have `__iter__` and `__next__` methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/uvicorn/server.py\u001b[0m in \u001b[0;36mserve\u001b[0;34m(self, sockets)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msockets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture_signals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_serve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msockets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/uvicorn/server.py\u001b[0m in \u001b[0;36mcapture_signals\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;31m# done LIFO, see https://stackoverflow.com/questions/48434964\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcaptured_signal\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_captured_signals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m             \u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_signal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaptured_signal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhandle_exit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFrameType\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "nest_asyncio.apply()\n",
        "uvicorn.run(app, port=8000)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}